#### ğŸ§ Projet 2 â€“ Ingestion & Validation CSV

Ce projet montre comment construire un pipeline dâ€™ingestion simple mais robuste :
- Extraction dâ€™un CSV en ligne
- VÃ©rification de lâ€™intÃ©gritÃ©
- Nettoyage
- Validation statistique
- Export final

Dataset utilisÃ© : sales_success.csv de Plotly.
__________________________________
#### ğŸ“‚ Structure
``` bash
projet2_ingestion_csv/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ final/
â”‚
â””â”€â”€ src/
    â”œâ”€â”€ extract.py
    â”œâ”€â”€ transform.py
    â”œâ”€â”€ validate.py
    â””â”€â”€ load.py
```
___________________________________
#### âš™ï¸ Pipeline

1ï¸âƒ£ Extract

TÃ©lÃ©charge le fichier CSV depuis internet.
```bash
python extract.py
```

2ï¸âƒ£ Transform
- Nettoyage basique
- Normalisation des noms de colonnes
- VÃ©rification des types
```bash
python transform.py
```

3ï¸âƒ£ Validate

Affiche :
- aperÃ§u des donnÃ©es
- statistiques
- vÃ©rification NA et incohÃ©rences
```bash
python validate.py
```

4ï¸âƒ£ Load

GÃ©nÃ¨re un fichier analytique final.
```bash
python load.py
```
_______________________________
***Fichiers gÃ©nÃ©rÃ©s :***

data/raw/sales.csv

data/processed/sales_clean.csv

data/final/final_sales.csv
_______________________________
#### ğŸ§¹ AmÃ©liorations possibles

- Ajout de rÃ¨gles mÃ©tier (seuils, anomalies)
- IntÃ©gration dâ€™un data quality checker (Great Expectations)
- Stockage dans un data lake (S3, ADLS)
